version: '3.8'

services:
  socar-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: socar-api
    ports:
      - "9000:9000"
    environment:
      # Azure AI Foundry Configuration
      - BASE_URL=${BASE_URL}
      - API_KEY=${API_KEY}
      
      # Model Configuration
      - OCR_MODEL=${OCR_MODEL:-Llama-4-Maverick-17B-128E-Instruct-FP8}
      - CHAT_MODEL=${CHAT_MODEL:-Llama-4-Maverick-17B-128E-Instruct-FP8}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-BAAI/bge-large-en-v1.5}
      
      # OCR Processing Settings
      - OCR_DPI_SCALE=${OCR_DPI_SCALE:-1.5}
      - OCR_MAX_TOKENS=${OCR_MAX_TOKENS:-4000}
      - JPEG_QUALITY=${JPEG_QUALITY:-90}
      
      # Knowledge Base Settings
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-200}
      - TOP_K_RESULTS=${TOP_K_RESULTS:-5}
      
      # Vector Database Configuration
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=${PINECONE_INDEX_NAME:-hackathon}
      - PINECONE_CLOUD=${PINECONE_CLOUD:-aws}
      - PINECONE_REGION=${PINECONE_REGION:-us-east-1}
      
      # API Server Settings
      - API_HOST=0.0.0.0
      - API_PORT=9000
    volumes:
      # Mount logs directory for persistence
      - ./logs:/app/logs
      # Optional: mount data directory if needed
      - ./hackathon_data:/app/hackathon_data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - socar-network

networks:
  socar-network:
    driver: bridge
